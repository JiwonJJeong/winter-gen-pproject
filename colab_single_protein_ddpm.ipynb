{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-Protein DDPM Training\n",
    "\n",
    "This notebook trains a DDPM model on **one specific protein** by learning to denoise different conformational states (frames) from an MD trajectory.\n",
    "\n",
    "**Workflow:**\n",
    "1. Specify protein name and parameters\n",
    "2. Dynamically create/load trajectory data for that protein\n",
    "3. Train DDPM to denoise frames\n",
    "4. Generate and evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check environment\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"✓ Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"✓ Running locally\")\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q omegaconf pandas tqdm numpy matplotlib\n",
    "\n",
    "import torch\n",
    "print(f\"\\n✓ PyTorch {torch.__version__}\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload gen_model Code\n",
    "\n",
    "Upload **only** `gen_model.zip` (just the code, NO data needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload gen_model code\n",
    "# Create gen_model.zip locally: zip -r gen_model.zip gen_model/\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"Upload gen_model.zip (code only, no data)\")\n",
    "    uploaded = files.upload()\n",
    "    !unzip -q gen_model.zip\n",
    "    print(\"\\n✓ Code extracted\")\n",
    "    !ls gen_model/\n",
    "else:\n",
    "    print(\"Not on Colab - assuming gen_model/ exists\")\n",
    "    !ls gen_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Protein Configuration\n",
    "\n",
    "**Specify your protein here** - data will be created automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# ============================================================================\n",
    "# PROTEIN CONFIGURATION - Change these for your protein\n",
    "# ============================================================================\n",
    "\n",
    "protein_config = OmegaConf.create({\n",
    "    # Protein specification\n",
    "    'protein': {\n",
    "        'name': '4o66_C',        # Protein name (will create folder data/4o66_C/)\n",
    "        'replica': 1,            # Replica number\n",
    "        'num_frames': 200,       # Number of frames in trajectory\n",
    "        'num_residues': 100,     # Number of residues\n",
    "        \n",
    "        # Data splits (by frame index)\n",
    "        'train_early_ratio': 0.3,  # First 30% of frames for early training\n",
    "        'train_ratio': 0.4,         # Next 40% for main training\n",
    "        'val_ratio': 0.15,          # Next 15% for validation\n",
    "        # Remaining 15% for test\n",
    "    },\n",
    "    \n",
    "    # If you have REAL data, set this to True and provide download method\n",
    "    'use_real_data': False,  # Set to True if downloading real data\n",
    "    'data_source': None,     # URL, Google Drive path, etc.\n",
    "    \n",
    "    # Diffusion parameters\n",
    "    'diffusion': {\n",
    "        'timesteps': 500,      # 100=fast test, 500=balanced, 1000=high quality\n",
    "        'beta_start': 0.0001,\n",
    "        'beta_end': 0.02,\n",
    "    },\n",
    "    \n",
    "    # Model architecture\n",
    "    'model': {\n",
    "        'hidden_dim': 256,     # 128=small, 256=balanced, 512=large\n",
    "        'time_emb_dim': 128,\n",
    "    },\n",
    "    \n",
    "    # Training\n",
    "    'training': {\n",
    "        'batch_size': 8,       # Reduce if OOM (8→4→2)\n",
    "        'num_epochs': 100,     # 50=quick, 100=balanced, 200=thorough\n",
    "        'learning_rate': 1e-4,\n",
    "        'num_workers': 2,\n",
    "        'save_every': 10,\n",
    "    },\n",
    "    \n",
    "    # Inference\n",
    "    'inference': {\n",
    "        'num_samples': 5,\n",
    "        'denoise_steps': 500,\n",
    "    },\n",
    "})\n",
    "\n",
    "print(\"Protein Configuration:\")\n",
    "print(f\"  Name: {protein_config.protein.name}\")\n",
    "print(f\"  Replica: {protein_config.protein.replica}\")\n",
    "print(f\"  Frames: {protein_config.protein.num_frames}\")\n",
    "print(f\"  Residues: {protein_config.protein.num_residues}\")\n",
    "print(f\"  Diffusion steps: {protein_config.diffusion.timesteps}\")\n",
    "print(f\"  Training epochs: {protein_config.training.num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create/Load Protein Data\n",
    "\n",
    "This creates the data structure for your specified protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "prot_cfg = protein_config.protein\n",
    "PROTEIN_FULL_NAME = f\"{prot_cfg.name}_R{prot_cfg.replica}\"\n",
    "\n",
    "print(f\"Setting up data for: {PROTEIN_FULL_NAME}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if protein_config.use_real_data:\n",
    "    # ========== OPTION A: Download/Load Real Data ==========\n",
    "    print(\"Loading real data...\")\n",
    "    \n",
    "    # Customize this based on your data source\n",
    "    # Example options:\n",
    "    \n",
    "    # From URL:\n",
    "    # !wget -O data.tar.gz {protein_config.data_source}\n",
    "    # !tar -xzf data.tar.gz\n",
    "    \n",
    "    # From Google Drive:\n",
    "    # from google.colab import drive\n",
    "    # drive.mount('/content/drive')\n",
    "    # !cp -r /content/drive/MyDrive/md_data/{prot_cfg.name} data/\n",
    "    \n",
    "    # From Google Drive file ID:\n",
    "    # !pip install -q gdown\n",
    "    # !gdown {protein_config.data_source} -O data.zip\n",
    "    # !unzip -q data.zip\n",
    "    \n",
    "    print(\"✓ Real data loaded\")\n",
    "    \n",
    "else:\n",
    "    # ========== OPTION B: Create Synthetic Data ==========\n",
    "    print(\"Creating synthetic trajectory data...\")\n",
    "    \n",
    "    # Create directory\n",
    "    protein_dir = f'data/{prot_cfg.name}'\n",
    "    os.makedirs(protein_dir, exist_ok=True)\n",
    "    \n",
    "    # Create trajectory: [num_frames, num_residues, 14 atoms, xyz]\n",
    "    trajectory = np.random.randn(\n",
    "        prot_cfg.num_frames,\n",
    "        prot_cfg.num_residues,\n",
    "        14,  # atom14 representation\n",
    "        3    # x, y, z\n",
    "    ).astype(np.float32)\n",
    "    \n",
    "    # Normalize to reasonable protein scale\n",
    "    trajectory = trajectory * 5.0  # ~5 Angstrom std deviation\n",
    "    \n",
    "    # Save trajectory\n",
    "    traj_path = f'{protein_dir}/{PROTEIN_FULL_NAME}_latent.npy'\n",
    "    np.save(traj_path, trajectory)\n",
    "    print(f\"  ✓ Created: {traj_path}\")\n",
    "    print(f\"    Shape: {trajectory.shape}\")\n",
    "    print(f\"    Size: {trajectory.nbytes / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Create atlas.csv (sequence mapping)\n",
    "atlas_data = {\n",
    "    'name': [PROTEIN_FULL_NAME],\n",
    "    'seqres': ['A' * prot_cfg.num_residues]  # Dummy sequence\n",
    "}\n",
    "os.makedirs('data', exist_ok=True)\n",
    "pd.DataFrame(atlas_data).to_csv('data/atlas.csv', index=False)\n",
    "print(f\"\\n  ✓ Created: data/atlas.csv\")\n",
    "\n",
    "# Create frame splits\n",
    "train_early_end = int(prot_cfg.num_frames * prot_cfg.train_early_ratio)\n",
    "train_end = int(prot_cfg.num_frames * (prot_cfg.train_early_ratio + prot_cfg.train_ratio))\n",
    "val_end = int(prot_cfg.num_frames * (prot_cfg.train_early_ratio + prot_cfg.train_ratio + prot_cfg.val_ratio))\n",
    "\n",
    "splits_data = {\n",
    "    'name': [PROTEIN_FULL_NAME],\n",
    "    'train_early_end': [train_early_end],\n",
    "    'train_end': [train_end],\n",
    "    'val_end': [val_end],\n",
    "}\n",
    "\n",
    "os.makedirs('gen_model/splits', exist_ok=True)\n",
    "pd.DataFrame(splits_data).to_csv('gen_model/splits/frame_splits.csv', index=False)\n",
    "print(f\"  ✓ Created: gen_model/splits/frame_splits.csv\")\n",
    "\n",
    "print(f\"\\nData splits (by frame index):\")\n",
    "print(f\"  Train early: frames 0-{train_early_end} ({train_early_end} frames)\")\n",
    "print(f\"  Train: frames {train_early_end}-{train_end} ({train_end - train_early_end} frames)\")\n",
    "print(f\"  Val: frames {train_end}-{val_end} ({val_end - train_end} frames)\")\n",
    "print(f\"  Test: frames {val_end}-{prot_cfg.num_frames} ({prot_cfg.num_frames - val_end} frames)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"✓ Data ready for protein: {PROTEIN_FULL_NAME}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Configure Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from gen_model.simple_train import SimpleDDPM, SimpleDenoiseModel, train_ddpm\n",
    "from gen_model.simple_inference import (\n",
    "    sample_from_noise, denoise_frame, load_checkpoint, test_with_dataset\n",
    ")\n",
    "from gen_model.dataset import MDGenDataset\n",
    "\n",
    "print(\"✓ Modules imported\")\n",
    "\n",
    "# Create dataset config\n",
    "data_config = OmegaConf.create({\n",
    "    'data_dir': 'data',\n",
    "    'atlas_csv': 'data/atlas.csv',\n",
    "    'train_split': 'gen_model/splits/frame_splits.csv',\n",
    "    'suffix': '_latent',\n",
    "    'frame_interval': None,\n",
    "    'crop_ratio': 0.95,\n",
    "    'min_t': 0.01,\n",
    "    \n",
    "    # Single protein filters\n",
    "    'pep_name': prot_cfg.name,     # Only load this protein\n",
    "    'replica': prot_cfg.replica,   # Only load this replica\n",
    "})\n",
    "\n",
    "print(f\"\\nDataset config:\")\n",
    "print(f\"  Protein: {data_config.pep_name}\")\n",
    "print(f\"  Replica: {data_config.replica}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "print(\"Loading datasets...\\n\")\n",
    "\n",
    "train_dataset = MDGenDataset(\n",
    "    args=data_config,\n",
    "    diffuser=None,\n",
    "    mode='train',\n",
    "    repeat=1,\n",
    "    num_consecutive=1,\n",
    "    stride=1\n",
    ")\n",
    "\n",
    "val_dataset = MDGenDataset(\n",
    "    args=data_config,\n",
    "    diffuser=None,\n",
    "    mode='val',\n",
    "    repeat=1,\n",
    "    num_consecutive=1,\n",
    "    stride=1\n",
    ")\n",
    "\n",
    "print(f\"✓ Training frames: {len(train_dataset)}\")\n",
    "print(f\"✓ Validation frames: {len(val_dataset)}\")\n",
    "\n",
    "# Check sample\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nSample keys: {list(sample.keys())}\")\n",
    "\n",
    "# Get dimensions\n",
    "if 'atom14_pos' in sample:\n",
    "    sample_data = sample['atom14_pos']\n",
    "elif 'rigids_0' in sample:\n",
    "    sample_data = sample['rigids_0'][..., 4:]\n",
    "else:\n",
    "    raise ValueError(\"Unknown data format\")\n",
    "\n",
    "if len(sample_data.shape) == 3:\n",
    "    n_residues = sample_data.shape[0]\n",
    "    in_channels = sample_data.shape[1] * sample_data.shape[2]\n",
    "else:\n",
    "    n_residues = sample_data.shape[0]\n",
    "    in_channels = sample_data.shape[1]\n",
    "\n",
    "print(f\"\\nData shape: {sample_data.shape}\")\n",
    "print(f\"Residues: {n_residues}\")\n",
    "print(f\"Flattened channels: {in_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Create diffusion scheduler\n",
    "diffusion = SimpleDDPM(\n",
    "    timesteps=protein_config.diffusion.timesteps,\n",
    "    beta_start=protein_config.diffusion.beta_start,\n",
    "    beta_end=protein_config.diffusion.beta_end\n",
    ").to(device)\n",
    "\n",
    "print(f\"✓ Diffusion: {protein_config.diffusion.timesteps} steps\")\n",
    "\n",
    "# Create model\n",
    "model = SimpleDenoiseModel(\n",
    "    in_channels=in_channels,\n",
    "    hidden_dim=protein_config.model.hidden_dim,\n",
    "    time_emb_dim=protein_config.model.time_emb_dim\n",
    ")\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"✓ Model: {n_params:,} parameters (~{n_params*4/1024/1024:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Training on {PROTEIN_FULL_NAME}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "save_dir = f'checkpoints/{prot_cfg.name}_ddpm'\n",
    "\n",
    "train_ddpm(\n",
    "    dataset=train_dataset,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    device=device,\n",
    "    batch_size=protein_config.training.batch_size,\n",
    "    num_epochs=protein_config.training.num_epochs,\n",
    "    lr=protein_config.training.learning_rate,\n",
    "    save_dir=save_dir,\n",
    "    save_every=protein_config.training.save_every\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ Training complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "import glob\n",
    "\n",
    "ckpts = sorted(glob.glob(f\"{save_dir}/*.pt\"))\n",
    "if ckpts:\n",
    "    model, epoch, _ = load_checkpoint(ckpts[-1], model, device)\n",
    "    print(f\"✓ Loaded checkpoint from epoch {epoch}\")\n",
    "\n",
    "# Test denoising\n",
    "print(f\"\\nTesting denoising on {protein_config.inference.num_samples} validation frames...\\n\")\n",
    "\n",
    "results = test_with_dataset(\n",
    "    model, diffusion, val_dataset, device,\n",
    "    num_samples=protein_config.inference.num_samples\n",
    ")\n",
    "\n",
    "# Statistics\n",
    "mse_values = [r['mse'] for r in results]\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Results for {PROTEIN_FULL_NAME}:\")\n",
    "print(f\"  Mean MSE: {np.mean(mse_values):.6f}\")\n",
    "print(f\"  Std MSE:  {np.std(mse_values):.6f}\")\n",
    "print(f\"  Min MSE:  {np.min(mse_values):.6f}\")\n",
    "print(f\"  Max MSE:  {np.max(mse_values):.6f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new conformations from noise\n",
    "print(\"Generating new samples from noise...\\n\")\n",
    "\n",
    "shape = (3, n_residues, in_channels)\n",
    "generated = sample_from_noise(\n",
    "    model, diffusion, shape, device,\n",
    "    num_steps=protein_config.inference.denoise_steps\n",
    ")\n",
    "\n",
    "# Save\n",
    "output_dir = f'outputs/{prot_cfg.name}_ddpm'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i in range(3):\n",
    "    path = f'{output_dir}/generated_sample_{i}.npy'\n",
    "    np.save(path, generated[i].cpu().numpy())\n",
    "    print(f\"  Saved: {path}\")\n",
    "\n",
    "# Save test results\n",
    "for i, r in enumerate(results):\n",
    "    np.save(f'{output_dir}/test_{i}_original.npy', r['original'])\n",
    "    np.save(f'{output_dir}/test_{i}_denoised.npy', r['denoised'])\n",
    "\n",
    "print(f\"\\n✓ Results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(range(len(mse_values)), mse_values, color='steelblue')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'Reconstruction Error\\n{PROTEIN_FULL_NAME}')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(mse_values, bins=10, edgecolor='black', color='steelblue')\n",
    "plt.xlabel('MSE')\n",
    "plt.ylabel('Count')\n",
    "plt.title('MSE Distribution')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(mse_values, 'o-', color='steelblue')\n",
    "plt.axhline(np.mean(mse_values), color='red', linestyle='--', label='Mean')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE Trend')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Saved: {output_dir}/analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package results\n",
    "!zip -rq {prot_cfg.name}_results.zip {save_dir} {output_dir}\n",
    "\n",
    "print(f\"\\nResults packaged: {prot_cfg.name}_results.zip\")\n",
    "print(f\"  Checkpoints: {save_dir}/\")\n",
    "print(f\"  Outputs: {output_dir}/\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    files.download(f'{prot_cfg.name}_results.zip')\n",
    "    print(\"\\n✓ Download started\")\n",
    "else:\n",
    "    print(f\"\\n✓ Saved locally as {prot_cfg.name}_results.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we did:**\n",
    "1. ✓ Configured protein: `{protein_config.protein.name}_R{protein_config.protein.replica}`\n",
    "2. ✓ Created {protein_config.protein.num_frames} frames of trajectory data\n",
    "3. ✓ Trained DDPM for {protein_config.training.num_epochs} epochs\n",
    "4. ✓ Evaluated denoising on validation frames\n",
    "5. ✓ Generated new conformations from noise\n",
    "\n",
    "**Key insight:** The model learned the conformational space of **one specific protein** by training on different frames from its MD trajectory.\n",
    "\n",
    "**To train on a different protein:**\n",
    "- Change `protein_config.protein.name`\n",
    "- Rerun from Step 3 onwards"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
