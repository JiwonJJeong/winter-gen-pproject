{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97478cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 4o66_C seems to exist at ./data/4o66_C. Skipping download.\n",
      "Warning: Could not detect timestep, using default 10.0 ps. Error: Cannot calculate timestep if trajectory has one frame.\n",
      "Preprocessing output ./data/4o66_C/4o66_C_R1.npy already exists. Skipping.\n",
      "Preprocessing output ./data/4o66_C/4o66_C_R2.npy already exists. Skipping.\n",
      "Preprocessing output ./data/4o66_C/4o66_C_R3.npy already exists. Skipping.\n",
      "Creating 4-way split (Early: 5.0ns, Ratios: [0.6, 0.2, 0.2])...\n",
      "Found 3 trajectory file(s) for 4o66_C.\n",
      "  4o66_C_R1: Total 10001, Timestep 10.0ps\n",
      "    Early: [0:500], Train: [500:6200], Val: [6200:8100], Test: [8100:10001]\n",
      "  4o66_C_R2: Total 10001, Timestep 10.0ps\n",
      "    Early: [0:500], Train: [500:6200], Val: [6200:8100], Test: [8100:10001]\n",
      "  4o66_C_R3: Total 10001, Timestep 10.0ps\n",
      "    Early: [0:500], Train: [500:6200], Val: [6200:8100], Test: [8100:10001]\n",
      "Updated splits saved to gen_model/splits/frame_splits.csv\n"
     ]
    }
   ],
   "source": [
    "!python scripts/download_and_prep.py 4o66_C --data_dir ./data --out_dir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa5bed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized args. Data dir: ./data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from gen_model.parsing import parse_train_args\n",
    "\n",
    "# Step 2: Set up arguments/config\n",
    "# We 'fake' the command line arguments so parse_train_args() doesn't crash\n",
    "# We provide a placeholder for --data_dir just to satisfy the 'required=True' check\n",
    "sys.argv = ['ipykernel_launcher.py', '--data_dir', './data']\n",
    "\n",
    "args = parse_train_args()\n",
    "\n",
    "# Now override with your actual desired notebook settings\n",
    "args.atlas = True\n",
    "args.data_dir = \"./data\"\n",
    "args.pep_name = \"4o66_C\"\n",
    "args.train_split = \"gen_model/splits/frame_splits.csv\"\n",
    "args.atlas_csv = \"gen_model/splits/atlas.csv\"\n",
    "args.batch_size = 8\n",
    "args.num_workers = 0\n",
    "\n",
    "print(f\"Successfully initialized args. Data dir: {args.data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee20d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load ./data/1a62_A/1a62_A_R1.npy: 'numpy.float64' object cannot be interpreted as an integer\n",
      "Warning: Could not load ./data/1a62_A/1a62_A_R2.npy: 'numpy.float64' object cannot be interpreted as an integer\n",
      "Warning: Could not load ./data/1a62_A/1a62_A_R3.npy: 'numpy.float64' object cannot be interpreted as an integer\n",
      "Warning: Could not load ./data/4o66_C/4o66_C_R1.npy: 'numpy.float64' object cannot be interpreted as an integer\n",
      "Warning: Could not load ./data/4o66_C/4o66_C_R2.npy: 'numpy.float64' object cannot be interpreted as an integer\n",
      "Warning: Could not load ./data/4o66_C/4o66_C_R3.npy: 'numpy.float64' object cannot be interpreted as an integer\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m trainset \u001b[38;5;241m=\u001b[39m MDGenDataset(args, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 2. Setup the DataLoader\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# num_workers=0 is often safer for debugging inside a notebook to avoid multiprocessing issues\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Validation set\u001b[39;00m\n\u001b[1;32m     19\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m MDGenDataset(args, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/winter-gen-pproject/lib/python3.10/site-packages/torch/utils/data/dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/winter-gen-pproject/lib/python3.10/site-packages/torch/utils/data/sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from gen_model.dataset import MDGenDataset\n",
    "\n",
    "# 1. Initialize the dataset\n",
    "# This will use the args.data_dir and args.train_split you defined in the previous step\n",
    "trainset = MDGenDataset(args, mode='train')\n",
    "\n",
    "# 2. Setup the DataLoader\n",
    "# num_workers=0 is often safer for debugging inside a notebook to avoid multiprocessing issues\n",
    "train_loader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "\n",
    "# Validation set\n",
    "val_dataset = MDGenDataset(args, mode='val')\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "\n",
    "# Test set\n",
    "test_dataset = MDGenDataset(args, split_csv, mode='test')\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "\n",
    "# 3. Fetch one batch to verify everything is working\n",
    "try:\n",
    "    batch = next(iter(train_loader))\n",
    "    print(\"Successfully loaded a train batch!\")\n",
    "    \n",
    "    # Print keys to see what data we have (e.g., 'pos', 'seq', 'mask')\n",
    "    print(f\"Batch keys: {batch.keys()}\")\n",
    "    \n",
    "    # Check the shape of the coordinates if available\n",
    "    if 'pos' in batch:\n",
    "        print(f\"Coordinates shape: {batch['pos'].shape}\")\n",
    "    \n",
    "    batch = next(iter(val_loader))\n",
    "    print(\"Successfully loaded a val batch!\")\n",
    "    \n",
    "    # Check the shape of the coordinates if available\n",
    "    if 'pos' in batch:\n",
    "        print(f\"Coordinates shape: {batch['pos'].shape}\")   \n",
    "\n",
    "    batch = next(iter(test_loader))\n",
    "    print(\"Successfully loaded a test batch!\")\n",
    "    \n",
    "    # Check the shape of the coordinates if available\n",
    "    if 'pos' in batch:\n",
    "        print(f\"Coordinates shape: {batch['pos'].shape}\")   \n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading batch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7cc558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 76])\n",
      "torch.Size([8, 1, 76, 7, 2])\n",
      "torch.Size([8, 1, 76, 3, 3])\n",
      "torch.Size([8, 1, 76, 3])\n"
     ]
    }
   ],
   "source": [
    "# These are the training inputs to be used in the model\n",
    "batch = next(iter(train_loader))\n",
    "print(batch['seqres'].shape)\n",
    "print(batch['clean_torsions'].shape)\n",
    "print(batch['clean_rots'].shape)\n",
    "print(batch['clean_trans'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b20df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 76])\n",
      "torch.Size([8, 76, 7])\n"
     ]
    }
   ],
   "source": [
    "# These are some additional tensors to multiply in the objective function\n",
    "print(batch['mask'].shape)\n",
    "print(batch['torsion_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d386f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 76, 37, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the \"ground truth\"\n",
    "batch['clean_atom37'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69234f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4o66_C_R3', '4o66_C_R1', '4o66_C_R1', '4o66_C_R1', '4o66_C_R3', '4o66_C_R1', '4o66_C_R1', '4o66_C_R2']\n",
      "tensor([[6434],\n",
      "        [ 260],\n",
      "        [9198],\n",
      "        [7580],\n",
      "        [7887],\n",
      "        [9299],\n",
      "        [9764],\n",
      "        [ 619]])\n"
     ]
    }
   ],
   "source": [
    "# This is some metadata about the batch. The frame indices might be used in the model\n",
    "print(batch['name'])\n",
    "print(batch['frame_indices'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winter-gen-pproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
