{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97478cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 4o66_C seems to exist at ./data/4o66_C. Skipping download.\n",
      "Detected timestep: 10.0 ps\n",
      "Preprocessing output ./data/4o66_C/4o66_C_R1.npy already exists. Skipping.\n",
      "Preprocessing output ./data/4o66_C/4o66_C_R2.npy already exists. Skipping.\n",
      "Preprocessing output ./data/4o66_C/4o66_C_R3.npy already exists. Skipping.\n",
      "Creating 4-way split (Early: 5.0ns, Ratios: [0.6, 0.2, 0.2])...\n",
      "Found 3 trajectory file(s) for 4o66_C.\n",
      "  4o66_C_R1: Total 10001, Timestep 10.0ps\n",
      "    Early: [0:500], Train: [500:6200], Val: [6200:8100], Test: [8100:10001]\n",
      "  4o66_C_R2: Total 10001, Timestep 10.0ps\n",
      "    Early: [0:500], Train: [500:6200], Val: [6200:8100], Test: [8100:10001]\n",
      "  4o66_C_R3: Total 10001, Timestep 10.0ps\n",
      "    Early: [0:500], Train: [500:6200], Val: [6200:8100], Test: [8100:10001]\n",
      "Updated splits saved to gen_model/splits/frame_splits.csv\n"
     ]
    }
   ],
   "source": [
    "!python scripts/download_and_prep.py 4o66_C --data_dir ./data --out_dir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa5bed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized args. Data dir: ./data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from gen_model.parsing import parse_train_args\n",
    "\n",
    "# Step 2: Set up arguments/config\n",
    "# We 'fake' the command line arguments so parse_train_args() doesn't crash\n",
    "# We provide a placeholder for --data_dir just to satisfy the 'required=True' check\n",
    "sys.argv = ['ipykernel_launcher.py', '--data_dir', './data']\n",
    "\n",
    "args = parse_train_args()\n",
    "\n",
    "# Now override with your actual desired notebook settings\n",
    "args.atlas = True\n",
    "args.data_dir = \"./data\"\n",
    "args.pep_name = \"4o66_C\"\n",
    "args.replica = 1\n",
    "args.atlas_csv = \"gen_model/splits/atlas.csv\"\n",
    "args.batch_size = 8\n",
    "args.num_workers = 0\n",
    "\n",
    "print(f\"Successfully initialized args. Data dir: {args.data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ee20d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded a train batch!\n",
      "Batch keys: dict_keys(['name', 'frame_indices', 'seqres', 'mask', 'torsion_mask', 'clean_trans', 'clean_rots', 'clean_torsions', 'clean_atom37'])\n",
      "Coordinates shape: torch.Size([8, 1, 76, 3])\n",
      "Successfully loaded a val batch!\n",
      "Coordinates shape: torch.Size([8, 1, 76, 3])\n",
      "Successfully loaded a test batch!\n",
      "Coordinates shape: torch.Size([8, 1, 76, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from gen_model.dataset import MDGenDataset\n",
    "\n",
    "# 1. Initialize the dataset\n",
    "# This will use the args.data_dir and args.train_split you defined in the previous step\n",
    "trainset = MDGenDataset(args, mode='train')\n",
    "\n",
    "# 2. Setup the DataLoader\n",
    "# num_workers=0 is often safer for debugging inside a notebook to avoid multiprocessing issues\n",
    "train_loader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "\n",
    "# Validation set\n",
    "val_dataset = MDGenDataset(args, mode='val')\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "\n",
    "# Test set\n",
    "test_dataset = MDGenDataset(args, mode='test')\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=args.num_workers,\n",
    ")\n",
    "\n",
    "# 3. Fetch one batch to verify everything is working\n",
    "try:\n",
    "    batch = next(iter(train_loader))\n",
    "    print(\"Successfully loaded a train batch!\")\n",
    "    \n",
    "    # Print keys to see what data we have (e.g., 'pos', 'seq', 'mask')\n",
    "    print(f\"Batch keys: {batch.keys()}\")\n",
    "    \n",
    "    # Check the shape of the coordinates if available\n",
    "    if 'clean_trans' in batch:\n",
    "        print(f\"Coordinates shape: {batch['clean_trans'].shape}\")\n",
    "    \n",
    "    batch = next(iter(val_loader))\n",
    "    print(\"Successfully loaded a val batch!\")\n",
    "    \n",
    "    # Check the shape of the coordinates if available\n",
    "    if 'clean_trans' in batch:\n",
    "        print(f\"Coordinates shape: {batch['clean_trans'].shape}\")   \n",
    "\n",
    "    batch = next(iter(test_loader))\n",
    "    print(\"Successfully loaded a test batch!\")\n",
    "    \n",
    "    # Check the shape of the coordinates if available\n",
    "    if 'clean_trans' in batch:\n",
    "        print(f\"Coordinates shape: {batch['clean_trans'].shape}\")   \n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading batch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7cc558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 76])\n",
      "torch.Size([8, 1, 76, 7, 2])\n",
      "torch.Size([8, 1, 76, 3, 3])\n",
      "torch.Size([8, 1, 76, 3])\n"
     ]
    }
   ],
   "source": [
    "# These are the training inputs to be used in the model\n",
    "batch = next(iter(train_loader))\n",
    "print(batch['seqres'].shape)\n",
    "print(batch['clean_torsions'].shape)\n",
    "print(batch['clean_rots'].shape)\n",
    "print(batch['clean_trans'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09b20df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 76])\n",
      "Masked per batch: tensor([4, 4, 4, 4, 4, 4, 4, 4])\n",
      "torch.Size([8, 76, 7])\n"
     ]
    }
   ],
   "source": [
    "# These are some additional tensors to multiply in the objective function\n",
    "print(batch['mask'].shape)\n",
    "# identify residue ids that are masked (zeroed out)\n",
    "num_masked = (batch['mask'] == 0).sum(dim=-1)\n",
    "print(\"Masked per batch:\", num_masked)\n",
    "print(batch['torsion_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d386f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 76, 37, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the \"ground truth\"\n",
    "batch['clean_atom37'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69234f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4o66_C_R1', '4o66_C_R1', '4o66_C_R1', '4o66_C_R1', '4o66_C_R1', '4o66_C_R1', '4o66_C_R1', '4o66_C_R1']\n",
      "tensor([[2760],\n",
      "        [2381],\n",
      "        [4450],\n",
      "        [5498],\n",
      "        [6154],\n",
      "        [5077],\n",
      "        [2869],\n",
      "        [1803]])\n"
     ]
    }
   ],
   "source": [
    "# This is some metadata about the batch. The frame indices might be used in the model\n",
    "print(batch['name'])\n",
    "print(batch['frame_indices'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winter-gen-pproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
